Andrew Briand and Libbey Brown
LING 567
Lab 7

Question 1: Description of non-verbal predicates in Tsova-Tush

An analysis of our corpus has shown that nonverbal predicates in Tsova-Tush operate very similarly to those in English, with the use of a copula 'a', glossed as 'be'.
We were unable to find examples that did not include a copula, so it appears that the copula is required for grammatical sentences.
Note that all of the examples in the corpus used present tense copula so we are focusing only on the present tense for the below analysis.

NP predicates
Sentences in Tsova-Tush using NP predicates are structured with the use of a copula 'a' ('be') similar to English sentences.
We were not able to locate any examples with a dropped copula so we determined the copula is required.
Neither NP in the sentence is inflected with case markers - both NPs are absolutive.
The copula 'a' takes an agreement marker that agrees with one of the NPs in the sentence, but it unclear to us which NP is the one which triggers agreement.

In sentences with only one NP (that may or may not also contain one demonstrative adjective), the copula agrees with the gender of the NP.
	
	Corpus sentence 120
	butː     b-a 
	moon     agreement.bd-be.PRESENT (Our IGT)
	moon CM (B/d) be (present) (Linguist provided IGT)
	This is the moon

	Corpus sentence 60
	e     mac'   b-a 
	this louse  agreement.bd-be.PRESENT (Our IGT)
	this louse CM (B/d) be (present) (Linguist provided IGT)
	This is a louse

	Corpus sentence 70
	e    k'eč' y-a 
	this wool  agreement.jd-be.PRESENT (Our IGT)
	this wool CM (F.sg) be (present) (Linguist provided IGT)
	This is wool

In sentences with the words 'man' or 'woman', the copula takes agreement markers with the gender of the 'man' or 'woman'.
The noun 'st'ak'' ('man') is a v/b noun, as are all male humans.
The noun 'pst'u' ('woman') is a j/d noun, as are all female humans.
Our literature states that, regardless of the grammatical gender of a noun, it will trigger v/b agreement if the noun is known to refer to a human man, and j/d agreement if the noun is known to refer to a human woman.
Essentially, this means 'shepherd' is a v/b noun in the settings that it refers to a male shepherd, and 'doctor' is a j/d noun in the settings it refers to a female doctor.

	Corpus sentence 1470
	e   st'ak' memcxor    v-a 
	this man   shepherd agreement.vb-be.PRESENT (our interpretation of IGT) 
	this man, person, human sheep-breeder CM (M.sg) be (present) (Linguist provided IGT)
	This man is a shepherd. 

	Corpus sentence 1490
	e    pst'u   dokt'ur   y-a 
	this woman   doctor    agreement.jd-be.PRESENT (our interpretation of IGT) 
	this woman doctor CM (F.sg) be (present) (Linguist provided IGT)
	This woman is a doctor


However, the pattern is less clear with non-human nouns that have different genders.

The following two sentences, translated by the linguist into English with different word orders, both have b/d gender agreement marked on the copula.
The noun 'don' ('horse') is a b/d gendered noun, and the noun 'sačukar' ('gift') is d/d gender, based on evaluating the agreement patterns of other sentences in the corpus.
In both of the following sentences, the copula is agreeing with the NP 'don' ('horse').

	Corpus sentence 1730
	e    don   sačukar    b-a 
	this horse gift      agreement.bd-be.PRESENT (our interpretation of IGT)
	this horse gift CM (B/d) be (present) (Linguist provided IGT)
	This horse is a gift.

	Corpus sentence 1740
	oquiⁿ        sačukar don      b-a 
	that.3sg.GEN gift    horse   agreement.bd-be.PRESENT (our interpretation of IGT)
	3S.GEN / that one gift horse CM (B/d) be (present) 
	His gift is a horse. 

In the above sentences, the agreement does not seem to vary based on word order, because the copula is agreeing with the noun 'don' in both word orders for the NPs.

Thus it is unclear what grammatical distinction is used to determine which noun the copula agrees with.
We decided to simply state that the copula 'a' (be) agrees with the subject, as with free word order and no case marking in these sentences, there does not seem to be a distinct subject or object in the NP copula sentences.

The following sentences using our machine translation vocabulary were added to the testsuite:

Non-verbal predicates: NP
Source: author
Vetted: f
Judgment: g
Phenomena: non-verbal predicates
pħu-i k'uit'i-i b-a
dog-PL cat-PL agreement.bb-be.PRESENT
The dogs are the cats

Non-verbal predicates: NP, needs copula
Source: author
Vetted: f
Judgment: u
Phenomena: non-verbal predicates
pħu-i k'uit'i-i 
dog-PL cat-PL 
The dogs are the cats

Non-verbal predicates: NP, incorrect agreement marker
Source: author
Vetted: f
Judgment: u
Phenomena: non-verbal predicates
pħu-i k'uit'i-i y-a
dog-PL cat-PL agreement.bb-be.PRESENT
The dogs are the cats

AP predicates:
Sentences in Tsova-Tush using adjectival predicates are, in general, structured similarly to sentences from English, with the use of a copula 'a' ('be') that takes agreement marking with the subject.
We were not able to locate any examples with a dropped copula so we determined the copula is required.
We were not able to find any examples of adjectives taking agreement markers with the subject.
If the subject is referring to a human person, the agreement on the copula is v/b for males and j/d for females.
If the subject is a non-human noun, then the copula takes agreement based on the grammatical gender of the noun.
The following sentences were found in our corpus:

	Corpus 1830
	so      k'ac'k'o     v-a 
	1st.sg   small      agreement.vbsg-be.PRESENT (our interpretation of IGT)
	1S little, small CM (M.sg) be (present) 
	I am small. (M) 

	Corpus 1840
	so      k'ac'k'o     y-a 
	1st.sg   small      agreement.jdsg-be.PRESENT (our interpretation of IGT)
	1S little, small CM (F.sg) be (present) 
	I am small. (F) 

	Corpus 6710
	t'at'eⁿ   b-a                  is     pħu 
	wet      agreement-be.PRESENT  this   dog (our interpretation of IGT)
	wet, damp CM (B/d) be (present) this one dog (provided IGT)
	This dog is wet. 

	Corpus 850
	txa    zorayš  laqeⁿ  max    b-a 
	today   very   high  price   agreement-be.PRESENT (our interpretation of IGT)
	today very, strongly tall, high price CM (B/d) be (present) (provided IGT)
	Today the price is very high
 
There were a handful of concepts, for example some sentences translated as "happy/pleased", that were expressed using a stative verb rather than copula + adjective, as in the example below:

	bader-i-n      zorayš ɣosxet 
	child-PL-DAT   very    be.pleased.PRESENT.UNINFLECTED
	child PL DAT very, strongly be pleased.
	The children are very pleased.

However, this seemed to be restricted to specific one-off concepts, similar to the verb "pleased" in English.

The following sentences using our machine translation vocabulary were added to the testsuite:

Non-verbal predicates: AP
Source: author
Vetted: f
Judgment: g
Phenomena: non-verbal predicates
pħu-i maci b-a
dog-PL hungry agreement.bb-be.PRESENT
The dogs are hungry

Non-verbal predicates: AP, incorrect agreement marker
Source: author
Vetted: f
Judgment: u
Phenomena: non-verbal predicates
pħu-i maci y-a
dog-PL hungry agreement.jd-be.PRESENT
The dogs are hungry

Non-verbal predicates: AP, needs copula
Source: author
Vetted: f
Judgment: u
Phenomena: non-verbal predicates
pħu-i maci 
dog-PL hungry 
The dogs are hungry

PP predicates:
As with AP and NP predicates, PP predicates are structured with the copula 'a' (be) which agrees with the subject.
Again, we were not able to locate any examples with a dropped copula so we determined the copula is required.
Tsova-Tush uses locative case marking rather than the preposition 'in'.  
The following sentences were found in our corpus:

	Corpus 1950
	mose   c'a-ħ       v-a 
	Mose   house-LOC   agreement.vb-be.PRESENT (our IGT)
	Mose (male name) house LOC CM (M.sg) be (present) (Linguist provided IGT)
	Mose is home.

	4380
	ilo   inc   kalika-ħ   v-a 
	Ilo   now   city-LOC   agreement.vb-be.PRESENT (our IGT)
	Ilo (male name) now city LOC CM (M.sg) be (present) (Linguist provided IGT)
	Ilo is in the city. 

The following sentences using our machine translation vocabulary were added to the testsuite:

Non-verbal predicates: PP
Source: author
Vetted: f
Judgment: g
Phenomena: non-verbal predicates
pħu-i mindor-ħ b-a
dog-PL park-LOC agreement.bb-be.PRESENT
The dogs are in the park

Non-verbal predicates: PP, needs copula
Source: author
Vetted: f
Judgment: u
Phenomena: non-verbal predicates
pħu-i mindor-ħ 
dog-PL park-LOC 
The dogs are in the park

Non-verbal predicates: PP, incorrect agreement
Source: author
Vetted: f
Judgment: g
Phenomena: non-verbal predicates
pħu-i mindor-ħ d-a
dog-PL park-LOC agreement.bb-be.PRESENT
The dogs are in the park

Non-verbal predicates: PP, incorrect case marker
Source: author
Vetted: f
Judgment: g
Phenomena: non-verbal predicates
pħu-i mindor-v b-a
dog-PL park agreement.bb-be.PRESENT
The dogs are in the park


Question 2: Implementation of phenomena

Treatment of PP complements:

We added the following rule as suggested in the lab instructions to turn locative nouns into PP's directly:

locative-pp-phrase := unary-phrase &
                      [ SYNSEM [ NON-LOCAL #nl,
                                 LOCAL.CAT [ HEAD adp & [ MOD < [ LOCAL intersective-mod &
                                                                        [ CAT.HEAD verb,
                                                                          CONT.HOOK.INDEX #xarg ] ] > ],
                                             VAL [ COMPS < >,
                                                   SUBJ < >,
                                                   SPR < > ]]],
                        C-CONT [ HOOK [ LTOP #ltop,
                                        INDEX #index,
                                        XARG #xarg ],
                                 RELS.LIST < arg12-ev-relation &
                                             [ PRED "_loc_p_rel",
                                               LBL #ltop,
                                               ARG0 #index,
                                               ARG1 #xarg,
                                               ARG2 #dtr ] >,
                                 HCONS.LIST < >  ],
                        ARGS < bare-np-phrase & [ SYNSEM [ NON-LOCAL #nl,
                                                           LOCAL [ CAT [ HEAD noun & [CASE loc] ],
                                                                   CONT.HOOK [ INDEX #dtr ] ] ] ] > ].

Treatment of AP complements:

Our grammar did not previously handle adjectives at all, so we added the following lexical type for them based on the basic-adjective-lex in matrix.tdl:

bbl-basic-adjective-lex := norm-sem-lex-item & intersective-mod-lex &
                           [ SYNSEM [ LOCAL [ CAT [ HEAD adj,
                                                    VAL [ COMPS < >,
                                                          SUBJ < >,
                                                          SPEC < >,
                                                          SPR.FIRST [ LOCAL [  CAT.HEAD noun,
                                                                               CONT.HOOK.XARG #index ] ] ] ] ],
                                      LKEYS.KEYREL event-relation &
                                            [ ARG0 #index ] ] ].

bbl-basic-adjective-lex :+
                          [ SYNSEM [ LOCAL.CONT.HOOK.XARG ref-ind & #xarg,
                                     LKEYS.KEYREL.ARG1 #xarg ] ].

To handle sentences involving both of these types of complements, we added the following copula verb type based on the type presented in the lab instructions:

copula-verb-lex := verb-lex & trans-first-arg-raising-lex-item-2
                   & verb-gender-agreement-intrans-rule-dtr &
                   [ SYNSEM.LOCAL [ CAT.VAL [ SUBJ < #subj >,
                                              COMPS < #comps >,
                                              SPR < >,
                                              SPEC < > ],
                                    CONT.HOOK.XARG #xarg ],
                     ARG-ST < #subj &
                              [ LOCAL [ CONT.HOOK.INDEX #xarg,
                                        CAT [ VAL [ SPR < >,
                                                    COMPS < > ],
                                              HEAD noun & [CASE abs] ] ] ],
                              #comps &
                              [ LOCAL.CAT [ VAL [ COMPS < > ],
                                            HEAD +jp ] ] > ].


We added verb-gender-agreement-intrans-rule-dtr as a super-type to enable gender agreement inflection on this verb as it inflects in the same way as other verbs. Our test suite sentences involved bb agreement which we had not previously handled so we added the following rules:

bb-lex-rule := verb-gender-agreement-intrans-lex-rule-super &
               [ SYNSEM.LOCAL.CAT.VAL.SUBJ.FIRST.LOCAL.CONT.HOOK.INDEX.PNG.GEND bb ].

bb-prefix :=
%prefix (* b-)
bb-lex-rule.

We then added the following lexical entry of that type:

a_2 := copula-verb-lex &
       [ STEM < "a" > ].

Treatment of NP complements:

Finally, to handle NP complements we added the following transitive verb with the appropriate predicate, and constraining both its subject and object to be in the absolutive case:

a := trans_impr_agr-verb-lex &
     [ STEM < "a" >,
       SYNSEM.LKEYS.KEYREL.PRED "_be_v_id_rel",
       SYNSEM.LOCAL.CAT.VAL [ SUBJ.FIRST.LOCAL.CAT.HEAD.CASE abs,
                              COMPS.FIRST.LOCAL.CAT.HEAD.CASE abs ] ].

Question 3: Machine translation

Sentence 15 does not translate in the machine translation setup. 
However, the MRS of the tree we are intending to parse in our grammar looks to match the sample MRS in the lab.

The sentence 'pħu-i maci b-a' parses with 2 trees.  Sentence and IGT repeated below:
	pħu-i maci b-a
	dog-PL hungry agreement.bb-be.PRESENT
	The dogs are hungry

Some of the ambiguity seems to be due to tense - there is one tree parsing correctly, with present tense, and another parsing with tense underspecified. 
Present tense is marked with no affix for the copula 'a' via 
	present_uninfl-lex-rule 
Prior to this week, our verbs were not parsing with underspecified tense, as we had made that particular position class a required class.
We will need to determine why the grammar is parsing trees without the tense.

Sentence 16 does not translate in the MT, but we are not surprised as this uses a locative noun rather than a preposition, so the MRS does not match.

We have significant ambiguity with this sentence, generating nine trees. Sentence and IGT repeated below:
	pħu-i mindor-ħ b-a
	dog-PL park-LOC agreement.bb-be.PRESENT
	The dogs are in the park
Some of the ambiguity is due to sentences being generated with both the transitive verb 'be' as well as our copula lexeme.
We will need to do additional work to reduce the number of sentences generating with PP predicates.

Sentence 17 does translate in the MT, but with 12 sentences output.
We expect 3 sentences, due to free word order in our language.  
From what we gather, it seems that some sentences are underspecified for tense, some are generated as present tense with our uninflected tense rule, and some are generated with present tense with an alternate spelling.
Interestingly, this issue was resolved last week for our intransitive verb, but there are clearly some additional things we'll need to do in morphology clean up for the transitive verbs.
We did confirm that our sentence 1 continues to translate with only two sentences generated.

In the grammar, it only generates a single parse.  Sentence and IGT repeated below:
	pħu-i k'uit'i-i b-a
	dog-PL cat-PL agreement.bb-be.PRESENT
	The dogs are the cats

Question 4:
We were not able to find enough information in our grammar or corpus for wh-questions and non-verbal predicates.  

Question 5:


Start of week performance on corpus, copied from Lab 6 end of week performance :
  How many items parsed? 109 out of 999
  What is the average number of parses per parsed item? 33.63
  How many parses did the most ambiguous item receive? 763
  What sources of ambiguity can you identify?
    Asyndetic coordination (combined with arugument optionality) continues to be problematic.  
    In the sentence with 763 parses, the sentence is interpreted as two coordinated sentences or multiple coordinated VPs in one sentence, with many trees from the different interpretations

The sentence with 763 parses, however, seems to be taken from dialogue and it's unclear to us if this is a grammatical single sentence:
e k'oc'ol ħalʷ y-opc-in , k'oc'ol y-a e 
this braid up CM (F.sg) weave, knit (+preradical CM) aorist formant , braid CM (y/y) be (present) this (Linguist's IGT)
braid up agreement-weave-aorist , braid agreement-be this (Our interpretation of the IGT)
She's making a braid, there's already a braid


Testsuite extended for Lab 7 with nonverbal predicates, run with Lab 6 grammar
	1. How many items parsed?
		37 of 106
	2. What is the average number of parses per parsed item?
		3.19
	3. How many parses did the most ambiguous item receive?
		52 
	4. What NEW sources of ambiguity can you identify?
		There are no new sources of ambiguity after adding the 10 new sentences to our testsuite.
		Copied from lab 6:	
		Two sentences received an excessive number of parses (48 and 52, respectively).
		For both of those two sentences, the main source of ambiguity appears to be extra lexical entries for the demonstrative adjectives 'eq' and 'is', the second of which is a verb.
		Having the word interpreted as a verb leads to asyndetic coordination of VPs and sentences.
		We should note that we have not worked on implementing demonstrative adjectives in our grammar.

Of the 10 new sentences added to the testsuite with nonverbal predicates, 2 of them were parsing, one of which was ungrammatical.

The sentence with the NP predicate was parsing, with the MRS correctly identifying dogs as ARG1 and cats as ARG2

	# 99: Non-verbal predicates: NP
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: non-verbal predicates
	pħu-i k'uit'i-i b-a
	dog-PL cat-PL agreement.bb-be.PRESENT
	The dogs are the cats

An ungrammatical sentence we developed for PP non-verbal predicates without the locative marker parsed, with similar semantics to the sentence above.
This sentences is not technically ungrammatical, but it parses without the locative semantics (basically translating as "The dogs are the park").


	# 104: Non-verbal predicates: PP, needs locative case marker
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: non-verbal predicates
	pħu-i mindor b-a
	dog-PL park agreement.bb-be.PRESENT
	The dogs are in the park

We determined this was not a great test sentence, as it does parse with a different meaning, so we changed it for the final run as follows:

	# 104: Non-verbal predicates: PP, incorrect case marker
	Source: author
	Vetted: f
	Judgment: g
	Phenomena: non-verbal predicates
	pħu-i mindor-v b-a
	dog-PL park agreement.bb-be.PRESENT
	The dogs are in the park

At the start of the week, the grammatical sentence with the locative case marking was not parsing.
At the start of the week, the grammatical sentence with the AP predicate was not parsing.
At the start of the week, the ungrammatical sentences without the copula were correctly not parsing.

End of week perforance on corpus:
	How many items parsed? 104 out of 999
	What is the average number of parses per parsed item? 40.36
	How many parses did the most ambiguous item receive? 844
	What NEW sources of ambiguity can you identify?
	  The most significant new source of ambiguity seems to be due to our verb agreement prefixes.
	  Prior to this week, our transitive 'be' verb was not set as an input to our gendered agreement prefixes, but was instead input to a handful of similarly-spelled prefixed automatically generated by the grammar.
	  Some of the prefixes have the same spelling (v/b plural is spelled the same as b/b singular and plural, for instance)
	  We have restricted our prefixes to only work with nouns of the correct gender to prevent multiple lexical rules being used to generate trees with the same spelling.
	  Since the corpus nouns are underspecified, we are seeing multiple lexical rules with the same spellings showing up in some trees, causing extra ambiguity.

End of week performance on testsuite:
	1. How many items parsed?
		39 of 106
	2. What is the average number of parses per parsed item?
		3.97
	3. How many parses did the most ambiguous item receive?
		52 
	4. What NEW sources of ambiguity can you identify?
		Our PP predicates are generating ambiguity, as discussed earlier.  There are no other new sources of ambiguity.

	
